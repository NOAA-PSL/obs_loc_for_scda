{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedefd74-b316-4024-be69-6d83c4edc3a0",
   "metadata": {},
   "source": [
    "# Effective Sample Size in 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66062a-b3d8-46c0-a102-f67be416d23e",
   "metadata": {},
   "source": [
    "Effective sample size is given by $n_{\\text{eff}}=\\frac{n}{1+(m-1)\\rho}$ where $n$ is the sample size, $m$ is the average group size, and $\\rho$ is correlation (in the intraclass correlation sense). We are working with data which can be grouped along both ensemble member and (lat,lon) pair. Therefore, as a first pass I will calculate $\\rho$ by considering each ensemble member to be its own group (80 groups). \n",
    "\n",
    "$$r={\\frac {K}{K-1}}\\cdot {\\frac {N^{-1}\\sum _{n=1}^{N}({\\bar {x}}_{n}-{\\bar {x}})^{2}}{s^{2}}}-{\\frac {1}{K-1}}$$\n",
    "where $K$ is the number of data values per group, and ${\\bar {x}}_{n}$ is the sample mean of the $n$th group.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ec409-21f1-4340-9da6-263a48131637",
   "metadata": {},
   "source": [
    "### Import packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3222c4-e5f2-4b8e-a13d-0101c3ca6c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1268e3-43ed-4d47-9bf0-bb999a2e1f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ess(sample_size, group_size, rho):\n",
    "    n_eff = sample_size/( 1 + (group_size-1)*rho)\n",
    "    return n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f8663ff-d661-4018-8d16-bc75e25953db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intraclass_correlation(arrayy):\n",
    "#arrayy is a 2-dimensional array with each row holding values corresponding to a single group\n",
    "    N = arrayy.shape[0] # number of groups\n",
    "    K = arrayy.shape[1] # number of data values per group\n",
    "    xbar = np.mean(arrayy)\n",
    "    s2 = np.var(arrayy)\n",
    "    grp_mean = np.mean(arrayy, axis=1)\n",
    "    grp_mean_centered = grp_mean - xbar\n",
    "    grp_var = np.mean(np.square(grp_mean_centered))\n",
    "    r = (K / (K-1)) * (grp_var / s2) - 1/(K-1)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4358ee4d-ec27-4e50-b469-8681f29e0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ess_from_array(arrayy):\n",
    "    sample_size = arrayy.size    # total number of samples\n",
    "    group_size = arrayy.shape[1] # number of data values per group\n",
    "    corr = intraclass_correlation(arrayy)\n",
    "    n_eff = ess(sample_size, group_size, corr)\n",
    "    return n_eff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96c1c3-c68c-40ee-bd49-3b8594bf4e0d",
   "metadata": {},
   "source": [
    "### A very synthetic example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3432139-2553-42d6-9252-8c361eec84ff",
   "metadata": {},
   "source": [
    "Let's contruct an array with 3 groups and 2 elements per group. The groups appear to be 'clustered', and hence we should see a large correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3497bcdb-45bf-4533-b015-54e9b9164adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [23 27]\n",
      " [ 7 13]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[23,27],[7, 13]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e8674e-f75d-4e59-8d57-34e75755dc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intraclass correlation is large: 0.9105988192296881\n"
     ]
    }
   ],
   "source": [
    "intra_corr = intraclass_correlation(x)\n",
    "print('Intraclass correlation is large: '+str(intra_corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65ff15ef-ea9b-4968-9984-e2a5f5744f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size is close to the number of groups: 3.1403766921718654\n"
     ]
    }
   ],
   "source": [
    "print('Effective sample size is close to the number of groups: '+str(compute_ess_from_array(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d28b1-022c-4878-a347-dfa4311b76c7",
   "metadata": {},
   "source": [
    "### Now consider SST in the Tropical Pacific"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b274116-a2ba-49d6-89d7-f07186533a7e",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "386bf073-0391-4051-8637-6b670f7373b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Where are we working\n",
    "proj_dir = '/Users/zstanley/Documents/git_repos/obs_loc_for_scda'\n",
    "plot_dir = proj_dir + '/plots/five_columns_error_in_kalman_gain/'\n",
    "my_data_dir = proj_dir + '/my_data/20151206.030000'\n",
    "nb_dir = proj_dir + '/notebooks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9723777f-dc0b-40aa-9d1e-e7066ba3b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "these_columns = {\n",
    "  'lons' : [-154.5, 35.5, 75.5, -150.5, 160.5],\n",
    "  'lats' : [-27.5, -49.5, -31.5, 12.5, 40.5],\n",
    "  'name' : ['South Pacific', 'Southern Ocean', 'Indian Ocean', 'Tropical Pacific', 'North Pacific'],\n",
    "  'save_name' : ['south_pacific2', 'southern_ocean2', 'indian_ocean2', 'tropical_pacific2', 'north_pacific']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c7910b-ae3d-47c3-9a52-5f6387439450",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load vertical columns\n",
    "south_pacific = xr.open_dataset(my_data_dir+'/five_columns_'+these_columns['save_name'][0]+'.nc')\n",
    "southern_ocean = xr.open_dataset(my_data_dir+'/five_columns_'+these_columns['save_name'][1]+'.nc')\n",
    "indian_ocean = xr.open_dataset(my_data_dir+'/five_columns_'+these_columns['save_name'][2]+'.nc')\n",
    "tropical_pacific = xr.open_dataset(my_data_dir+'/five_columns_'+these_columns['save_name'][3]+'.nc')\n",
    "north_pacific = xr.open_dataset(my_data_dir+'/five_columns_'+these_columns['save_name'][4]+'.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "931724c9-2bd3-4aaa-8957-a5c9983d52c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = north_pacific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04575109-2683-45ce-a7ee-24d8b4ddd27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_groups = ds['ens_mem'].size\n",
    "num_per_group = ds['lat'].size * ds['lon'].size\n",
    "sst = np.empty((num_groups, num_per_group))\n",
    "ast = np.empty((num_groups, num_per_group))\n",
    "ind = 0\n",
    "for lat in ds['lat'].values:\n",
    "    for lon in ds['lon'].values:\n",
    "        # sst\n",
    "        hold = ds['sst'].sel(lat=lat, lon=lon)\n",
    "        hold = hold - hold.mean('ens_mem')\n",
    "        hold = hold.to_numpy()\n",
    "        sst[:, ind] = hold\n",
    "        # ast\n",
    "        hold = ds['atm_T'].sel(atm_lev=126, lat=lat, lon=lon)\n",
    "        hold = hold - hold.mean('ens_mem')\n",
    "        hold = hold.to_numpy()\n",
    "        ast[:, ind] = hold\n",
    "        ind = ind + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bf39b3d-7901-4d01-b0b8-48390724c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective sample size for AST is: 206.3017495541281\n",
      "Effective sample size for SST is: 608.0227181984432\n"
     ]
    }
   ],
   "source": [
    "print('Effective sample size for AST is: '+str(compute_ess_from_array(ast)))\n",
    "print('Effective sample size for SST is: '+str(compute_ess_from_array(sst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb949b8-6da7-4a96-8114-940d6ba13b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
